<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Nokia 3310 Ringtone Maker</title>

    <!-- CSS Section -->
    <style>
        .container {
            max-width: 600px;
            margin: 0 auto;
            padding: 20px;
            font-family: Arial, sans-serif;
        }
        
        h1 {
            text-align: center;
            color: #0066CC;
        }
        
        textarea {
            width: 100%;
            margin-bottom: 10px;
            padding: 8px;
            border-radius: 4px;
            border: 1px solid #ccc;
        }
        
        button {
            background-color: #0066CC;
            color: white;
            border: none;
            padding: 10px 15px;
            border-radius: 4px;
            cursor: pointer;
            margin-right: 10px;
        }
        
        button:hover {
            background-color: #0055AA;
        }
        
        .status {
            margin-top: 15px;
            padding: 10px;
            border-radius: 4px;
            display: none;
        }
        
        .recording {
            background-color: #ffecec;
            color: #ff0000;
            display: block;
        }
        
        .download-link {
            display: none;
            margin-top: 15px;
            padding: 10px;
            text-decoration: none;
            background-color: #4CAF50;
            color: white;
            border-radius: 4px;
        }
        
        .download-link:hover {
            background-color: #45a049;
        }
    </style>
</head>

<body>

<!-- Header Section -->
<header>
    <div class="container">
        <h1>Nokia 3310 Ringtone Maker</h1>
    </div>
</header>

<!-- Main Content Section -->
<main class="container">
    <p>Enter your RTTTL code below or use the default example:</p>
    <textarea id="rtttl" rows="3" cols="60">d=4,o=5,b=100: 4a,8f,8g</textarea><br>

    <button id="createButton">Play & Record & Download</button>
    <button id="stopButton" style="display: none;">Stop Recording</button>
    
    <div id="statusMessage" class="status">Recording in progress...</div>
    <a id="downloadLink" class="download-link" href="#" download="nokia-ringtone.wav">Download Ringtone</a>

</main>

<!-- JavaScript Section -->
<script src="https://cdn.jsdelivr.net/npm/recorderjs@1.0.1/dist/recorder.js"></script>
<script>

    // GLOBAL STATE

    let g_toneLoaded = false;
    let g_synth = null;
    let g_currentPart = null;  // Keep track of the current part
    let g_audioContext = null;
    let g_mediaRecorder = null;
    let g_recordedChunks = [];
    let g_isRecording = false;
    let g_totalDuration = 0;
    let g_recordingTimeout = null;

    // EVENT BINDINGS

    document.getElementById('createButton').addEventListener('click', onCreateButtonClick);
    document.getElementById('stopButton').addEventListener('click', stopRecording);

    // EVENT HANDLERS

    async function onCreateButtonClick() {
        // TODO kmere What happens if clicked twice quickly?
        console.log("onCreateButtonClick");
        
        // Reset UI
        document.getElementById('downloadLink').style.display = 'none';
        document.getElementById('createButton').disabled = true;
        
        try {
            // Load Tone.js on first click
            if (!g_toneLoaded) {
                await loadTone();
                g_toneLoaded = true;
            }

            // Initialize audio context if not already created
            if (!g_audioContext) {
                g_audioContext = new (window.AudioContext || window.webkitAudioContext)();
            }

            // Initialize synth on first click if not already created
            if (!g_synth) {
                g_synth = new Tone.PulseOscillator({
                    frequency: 1000, // play high pitch
                    width: 0.05 // super narrow pulse
                }).toDestination();
            }

            await Tone.start();

            // Stop any previous transport
            Tone.Transport.stop();
            // Reset transport to beginning
            Tone.Transport.position = 0;

            // Dispose of previous part if it exists
            if (g_currentPart) {
                g_currentPart.dispose();
            }

            const {settings, notes} = parseRtttl(document.getElementById('rtttl').value);
            console.log(settings);
            console.log(notes);

            Tone.Transport.bpm.value = settings.bpm;

            let time = 0.0;
            const toneNotes = notes.map(n => {
                const res = {
                    time: time,
                    note: n.note,
                    dur: n.duration
                };
                time += Tone.Time(n.duration).toSeconds();
                return res;
            });
            console.log(toneNotes);
            
            // Calculate total duration in seconds
            g_totalDuration = time + 1; // Add 1 second buffer
            console.log("Total duration: " + g_totalDuration + " seconds");

            // Start recording
            startRecording();

            // Create new part
            g_currentPart = new Tone.Part((time, note) => {
                g_synth.frequency.setValueAtTime(Tone.Frequency(note.note).toFrequency(), time);
                g_synth.start(time);
                g_synth.stop(time + Tone.Time(note.dur).toSeconds()); // Stop after the note duration
            }, toneNotes.map(n => [n.time, n]))

            // Start the part at the beginning of the timeline
            g_currentPart.start(0);

            // Start the transport
            Tone.Transport.start();
            
            // Auto-stop recording after the total duration plus a small buffer
            g_recordingTimeout = setTimeout(() => {
                if (g_isRecording) {
                    stopRecording();
                }
            }, (g_totalDuration * 1000) + 500);
            
            // Show stop button
            document.getElementById('stopButton').style.display = 'inline-block';
            
        } catch (error) {
            console.error("Error in onCreateButtonClick:", error);
            document.getElementById('createButton').disabled = false;
        }
    }

    function startRecording() {
        g_recordedChunks = [];
        g_isRecording = true;
        
        // Show recording status
        document.getElementById('statusMessage').textContent = "Recording in progress...";
        document.getElementById('statusMessage').classList.add('recording');
        document.getElementById('statusMessage').style.display = 'block';
        
        // Create a MediaStream destination from Tone.js
        const dest = Tone.getContext().createMediaStreamDestination();
        g_synth.connect(dest);
        
        // Create MediaRecorder
        g_mediaRecorder = new MediaRecorder(dest.stream);
        
        g_mediaRecorder.ondataavailable = event => {
            if (event.data.size > 0) {
                g_recordedChunks.push(event.data);
            }
        };
        
        g_mediaRecorder.onstop = async () => {
            document.getElementById('statusMessage').textContent = "Processing audio...";

            // Process recorded audio chunks into 8000Hz mono WAV
            const originalBlob = new Blob(g_recordedChunks, { type: 'audio/wav' });
            const downsampledBlob = await downsampleAudio(originalBlob, 8000);
            const audioUrl = URL.createObjectURL(downsampledBlob);
            
            const downloadLink = document.getElementById('downloadLink');
            downloadLink.href = audioUrl;
            downloadLink.style.display = 'inline-block';
            
            document.getElementById('statusMessage').textContent = "Recording complete!";
            document.getElementById('statusMessage').classList.remove('recording');
            document.getElementById('stopButton').style.display = 'none';
            document.getElementById('createButton').disabled = false;
        };
        
        g_mediaRecorder.start();
    }
    
    function stopRecording() {
        if (g_isRecording && g_mediaRecorder) {
            g_isRecording = false;
            g_mediaRecorder.stop();
            
            // Stop the transport
            Tone.Transport.stop();
            
            // Clear the timeout if it exists
            if (g_recordingTimeout) {
                clearTimeout(g_recordingTimeout);
                g_recordingTimeout = null;
            }
        }
    }

    function loadTone() {
        return new Promise((resolve, reject) => {
            const script = document.createElement('script');
            script.src = "https://unpkg.com/tone";
            script.onload = resolve;
            script.onerror = reject;
            document.body.appendChild(script);
        });
    }

    // FUNCTIONS WITHOUT SIDE-EFFECTS

    function parseRtttl(rtttl) {
        const [settingsStr, nodesStr] = rtttl.split(':');
        console.log(settingsStr);
        console.log(nodesStr);
        const settings = parseRtttlSettings(settingsStr);
        console.log(settings);
        let notes = nodesStr.split(',')
            .map(parseRtttlNote);
        console.log(notes);
        notes = notes.map(n => convertRtttlNote(settings, n));
        console.log(notes);
        return {
            settings: settings,
            notes: notes
        };
    }

    function parseRtttlNote(noteStr) {
        const match = noteStr.match(/(\d*)([a-gp])(#?)(\.?)(\d*)/i);
        const [_, duration, note, sharp, halfExtend, octave] = match;
        return {
            duration: duration,
            note: note.toUpperCase(),
            sharp: !!sharp,
            octave: octave,
            halfExtend: !!halfExtend
        };
    }

    function parseRtttlSettings(settingsStr) {
        const settings = Object.fromEntries(
            settingsStr.split(',').map(s => s.split('='))
        );
        return {
            bpm: parseInt(settings.b || 63),
            octave: parseInt(settings.o || 5),
            duration: parseInt(settings.d || 4)
        };
    }

    function convertRtttlNote(settings, rtttlNote) {
        const duration = (rtttlNote.duration || settings.duration)
            + 'n'
            + (rtttlNote.halfExtend ? '.' : '');
        let note = rtttlNote.note === 'P' ? null : rtttlNote.note;
        if (!!note && rtttlNote.sharp) note += '#';
        if (!!note) note += rtttlNote.octave || settings.octave;
        return {
            duration: duration,
            note: note
        };
    }

    // AUDIO PROCESSING FUNCTIONS

    async function downsampleAudio(audioBlob, targetSampleRate) {
        return new Promise(async (resolve, reject) => {
            try {
                // Create audio context with desired sample rate
                const audioCtx = new (window.AudioContext || window.webkitAudioContext)({
                    sampleRate: targetSampleRate
                });
                
                // Create and register the AudioWorklet processor inline
                try {
                    // Define the processor code as a string
                    const processorCode = `
                        class DownsamplerProcessor extends AudioWorkletProcessor {
                          constructor() {
                            super();
                            this.recBuffers = [];
                            this.recLength = 0;
                            
                            // Listen for messages from the main thread
                            this.port.onmessage = (event) => {
                              if (event.data.message === 'complete') {
                                // Send the collected buffers back when processing is complete
                                this.port.postMessage({
                                  message: 'buffers',
                                  recBuffers: this.recBuffers,
                                  recLength: this.recLength
                                });
                              }
                            };
                          }
                
                          process(inputs, outputs) {
                            // Get input data (we expect mono or will convert to mono)
                            const inputChannels = inputs[0];
                            if (inputChannels.length === 0) return true;
                            
                            // Convert to mono if needed by averaging all channels
                            const monoData = new Float32Array(inputChannels[0].length);
                            
                            for (let i = 0; i < monoData.length; i++) {
                              let sum = 0;
                              for (let channel = 0; channel < inputChannels.length; channel++) {
                                sum += inputChannels[channel][i];
                              }
                              monoData[i] = sum / inputChannels.length;
                            }
                            
                            // Store the mono data
                            this.recBuffers.push(new Float32Array(monoData));
                            this.recLength += monoData.length;
                            
                            // Keep the processor alive
                            return true;
                          }
                        }
                
                        registerProcessor('downsampler-processor', DownsamplerProcessor);
                    `;
                    
                    // Create a Blob URL from the processor code
                    const blob = new Blob([processorCode], { type: 'application/javascript' });
                    const processorUrl = URL.createObjectURL(blob);
                    
                    // Load the processor from the Blob URL
                    await audioCtx.audioWorklet.addModule(processorUrl);
                    
                    // Clean up the Blob URL after it's loaded
                    URL.revokeObjectURL(processorUrl);
                } catch (e) {
                    console.error("Error setting up audio worklet:", e);
                    reject(e);
                    return;
                }
                
                // Create an audio source from the blob
                const fileReader = new FileReader();
                
                fileReader.onloadend = async () => {
                    try {
                        // Get the audio data
                        const arrayBuffer = fileReader.result;
                        const audioBuffer = await audioCtx.decodeAudioData(arrayBuffer);
                        
                        // Create a recorder node
                        const source = audioCtx.createBufferSource();
                        source.buffer = audioBuffer;
                        
                        // Create an AudioWorkletNode
                        const downsamplerNode = new AudioWorkletNode(audioCtx, 'downsampler-processor');
                        
                        // Set up message handling to receive processed buffers
                        downsamplerNode.port.onmessage = (event) => {
                            if (event.data.message === 'buffers') {
                                // Get the data from the processor
                                const recBuffers = event.data.recBuffers;
                                const recLength = event.data.recLength;
                                
                                // Concatenate all buffers
                                const result = new Float32Array(recLength);
                                let offset = 0;
                                for (let i = 0; i < recBuffers.length; i++) {
                                    result.set(recBuffers[i], offset);
                                    offset += recBuffers[i].length;
                                }
                                
                                // Create WAV blob with the target sample rate mono
                                const wavBlob = encodeWAV(result, targetSampleRate);
                                resolve(wavBlob);
                                
                                // Clean up
                                source.disconnect();
                                downsamplerNode.disconnect();
                            }
                        };
                        
                        // When done, notify the processor to send back the collected buffers
                        source.onended = () => {
                            downsamplerNode.port.postMessage({ message: 'complete' });
                        };
                        
                        // Connect the nodes
                        source.connect(downsamplerNode);
                        downsamplerNode.connect(audioCtx.destination);
                        
                        // Start processing
                        source.start(0);
                        
                    } catch (error) {
                        console.error("Error processing audio:", error);
                        reject(error);
                    }
                };
                
                fileReader.onerror = reject;
                fileReader.readAsArrayBuffer(audioBlob);
                
            } catch (error) {
                console.error("Error setting up audio context:", error);
                reject(error);
            }
        });
    }
                        
                        // Simple function to encode Float32Array as WAV
                        function encodeWAV(samples, sampleRate) {
                            const buffer = new ArrayBuffer(44 + samples.length * 2);
                            const view = new DataView(buffer);
                            
                            // RIFF header
                            writeString(view, 0, 'RIFF');
                            view.setUint32(4, 36 + samples.length * 2, true);
                            writeString(view, 8, 'WAVE');
                            
                            // fmt chunk
                            writeString(view, 12, 'fmt ');
                            view.setUint32(16, 16, true);
                            view.setUint16(20, 1, true); // PCM format
                            view.setUint16(22, 1, true); // Mono
                            view.setUint32(24, sampleRate, true);
                            view.setUint32(28, sampleRate * 2, true); // Byte rate
                            view.setUint16(32, 2, true); // Block align
                            view.setUint16(34, 16, true); // Bits per sample
                            
                            // data chunk
                            writeString(view, 36, 'data');
                            view.setUint32(40, samples.length * 2, true);
                            
                            // Write the PCM samples
                            let index = 44;
                            for (let i = 0; i < samples.length; i++) {
                                let s = Math.max(-1, Math.min(1, samples[i]));
                                s = s < 0 ? s * 0x8000 : s * 0x7FFF;
                                view.setInt16(index, s, true);
                                index += 2;
                            }
                            
                            return new Blob([buffer], { type: 'audio/wav' });
                        }
                        
                        // Helper to write strings to DataView
                        function writeString(view, offset, string) {
                            for (let i = 0; i < string.length; i++) {
                                view.setUint8(offset + i, string.charCodeAt(i));
                            }
                        }

</script>

</body>

</html>
